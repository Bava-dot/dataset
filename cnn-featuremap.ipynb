{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Step i. Load a small dataset (CIFAR-10)\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Step ii. Split the dataset\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Step iii. Visualize some samples\n",
    "def imshow(img, labels, class_names):\n",
    "    img = img / 2 + 0.5  # Unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.title(\"Labels: \" + \", \".join([class_names[labels[j]] for j in range(len(labels))]))\n",
    "    plt.show()\n",
    "\n",
    "class_names = train_dataset.classes\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "imshow(torchvision.utils.make_grid(images[:8]), labels[:8], class_names)\n",
    "\n",
    "# Step iv. Define CNN architecture with feature map functionality\n",
    "class SimpleCNN(nn.Module):\n",
    "    def _init_(self):\n",
    "        super(SimpleCNN, self)._init_()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)  # Convolutional layer\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 8 * 8, 128)  # Fully connected layer\n",
    "        self.fc2 = nn.Linear(128, 10)  # Output layer\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        feature_map = x  # Capture feature map after conv1\n",
    "        x = self.pool(feature_map)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 32 * 8 * 8)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x, feature_map  # Return the feature map for visualization\n",
    "\n",
    "# Initialize model\n",
    "model = SimpleCNN()\n",
    "\n",
    "# Step v. Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Step vi. Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Step vii. Train the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "num_epochs = 5\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs, _ = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_losses.append(running_loss / len(train_loader))\n",
    "    train_accuracies.append(100 * correct / total)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss / len(train_loader):.4f}, Accuracy: {100 * correct / total:.2f}%\")\n",
    "\n",
    "    # Validation step\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs, _ = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_losses.append(test_loss / len(test_loader))\n",
    "    test_accuracies.append(100 * correct / total)\n",
    "    print(f\"Test Loss: {test_loss / len(test_loader):.4f}, Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "\n",
    "# Step viii. Plot loss and accuracy graphs\n",
    "epochs = range(1, num_epochs + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_losses, label='Training Loss', marker='o')\n",
    "plt.plot(epochs, test_losses, label='Validation Loss', marker='o')\n",
    "plt.title('Loss Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_accuracies, label='Training Accuracy', marker='o')\n",
    "plt.plot(epochs, test_accuracies, label='Validation Accuracy', marker='o')\n",
    "plt.title('Accuracy Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Step ix. Visualize feature map\n",
    "def visualize_feature_map(model, loader):\n",
    "    model.eval()\n",
    "    images, _ = next(iter(loader))\n",
    "    images = images.to(device)\n",
    "    _, feature_map = model(images)\n",
    "\n",
    "    feature_map = feature_map[0].cpu().detach()  # First image in batch\n",
    "    n_filters = feature_map.size(0)\n",
    "\n",
    "    fig, axes = plt.subplots(1, min(n_filters, 8), figsize=(20, 5))\n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.imshow(feature_map[i], cmap='viridis')\n",
    "        ax.axis('off')\n",
    "    plt.suptitle('Feature Maps from First Convolutional Layer', fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "visualize_feature_map(model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "\n",
    "# Step 1: Load dataset using TensorFlow Datasets\n",
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'horses_or_humans',\n",
    "    split=['train', 'test'],\n",
    "    with_info=True,\n",
    "    as_supervised=True\n",
    ")\n",
    "\n",
    "# Step 2: Wrap TensorFlow dataset for PyTorch compatibility\n",
    "class TFDSWrapper(torch.utils.data.Dataset):\n",
    "    def _init_(self, tf_dataset, transform=None):\n",
    "        self.tf_dataset = list(tfds.as_numpy(tf_dataset))\n",
    "        self.transform = transform\n",
    "\n",
    "    def _len_(self):\n",
    "        return len(self.tf_dataset)\n",
    "\n",
    "    def _getitem_(self, idx):\n",
    "        image, label = self.tf_dataset[idx]\n",
    "        image = Image.fromarray(image)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Step 3: Define image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Resize images\n",
    "    transforms.ToTensor(),         # Convert images to PyTorch tensors\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize image data\n",
    "])\n",
    "\n",
    "# Apply transformations to train and test datasets\n",
    "train_dataset = TFDSWrapper(ds_train, transform=transform)\n",
    "test_dataset = TFDSWrapper(ds_test, transform=transform)\n",
    "\n",
    "# Step 4: Create DataLoaders for batching and shuffling\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Step 5: Visualize some images\n",
    "def imshow(img, labels, class_names):\n",
    "    img = img / 2 + 0.5  # Undo normalization\n",
    "    npimg = img.numpy()\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.title(\"Labels: \" + \", \".join([class_names[label] for label in labels]))\n",
    "    plt.show()\n",
    "\n",
    "class_names = ['Horse', 'Human']\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "imshow(torchvision.utils.make_grid(images[:8]), labels[:8], class_names)\n",
    "\n",
    "# Step 6: Define a simple CNN architecture\n",
    "class SimpleCNN(nn.Module):\n",
    "    def _init_(self):\n",
    "        super(SimpleCNN, self)._init_()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)  # Input: 3 channels (RGB), Output: 16 filters\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1) # Input: 16 filters, Output: 32 filters\n",
    "        self.fc1 = nn.Linear(32 * 32 * 32, 128)      # Fully connected layer\n",
    "        self.fc2 = nn.Linear(128, 2)                # Output layer for 2 classes (Horse/Human)\n",
    "        self.relu = nn.ReLU()                       # Activation function\n",
    "        self.pool = nn.MaxPool2d(2, 2)              # Pooling layer to downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))  # Convolution 1\n",
    "        feature_map = x               # Save feature map for visualization\n",
    "        x = self.pool(feature_map)    # Pooling 1\n",
    "        x = self.relu(self.conv2(x))  # Convolution 2\n",
    "        x = self.pool(x)              # Pooling 2\n",
    "        x = x.view(-1, 32 * 32 * 32)  # Flatten the tensor\n",
    "        x = self.relu(self.fc1(x))    # Fully connected layer 1\n",
    "        x = self.fc2(x)               # Fully connected layer 2 (output)\n",
    "        return x, feature_map\n",
    "\n",
    "# Step 7: Define loss function and optimizer\n",
    "model = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Step 8: Train the model with accuracy and loss tracking\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "num_epochs = 5\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Training loop\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()       # Reset gradients\n",
    "        outputs, _ = model(images)  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Compute loss\n",
    "        loss.backward()             # Backpropagation\n",
    "        optimizer.step()            # Update weights\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)  # Predictions\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_accuracy = 100 * correct / total\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.2f}%\")\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs, _ = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    test_accuracy = 100 * correct / total\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "# Step 9: Plot training and validation loss and accuracy\n",
    "epochs = range(1, num_epochs + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_losses, label='Training Loss', marker='o')\n",
    "plt.plot(epochs, test_losses, label='Validation Loss', marker='o')\n",
    "plt.title('Loss Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_accuracies, label='Training Accuracy', marker='o')\n",
    "plt.plot(epochs, test_accuracies, label='Validation Accuracy', marker='o')\n",
    "plt.title('Accuracy Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Step 10: Visualize feature maps\n",
    "def visualize_feature_map(model, loader):\n",
    "    model.eval()\n",
    "    images, _ = next(iter(loader))  # Get a batch of images\n",
    "    images = images.to(device)\n",
    "\n",
    "    _, feature_map = model(images)  # Get feature maps\n",
    "    feature_map = feature_map[0].cpu().detach()  # Extract feature map for the first image\n",
    "    n_filters = feature_map.size(0)\n",
    "\n",
    "    fig, axes = plt.subplots(1, min(n_filters, 8), figsize=(20, 5))\n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.imshow(feature_map[i], cmap='viridis')\n",
    "        ax.axis('off')\n",
    "    plt.suptitle('Feature Maps from First Convolutional Layer', fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "# Visualize feature maps\n",
    "visualize_feature_map(model, train_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
